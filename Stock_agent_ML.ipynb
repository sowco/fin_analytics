{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Загрузки\" data-toc-modified-id=\"Загрузки-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Загрузки</a></span></li><li><span><a href=\"#Функции\" data-toc-modified-id=\"Функции-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Функции</a></span><ul class=\"toc-item\"><li><span><a href=\"#Функции-загрузки\" data-toc-modified-id=\"Функции-загрузки-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Функции загрузки</a></span></li><li><span><a href=\"#Подгрузка-новых-данных-и-предсказание-на-новых-данных\" data-toc-modified-id=\"Подгрузка-новых-данных-и-предсказание-на-новых-данных-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Подгрузка новых данных и предсказание на новых данных</a></span></li><li><span><a href=\"#Создание-признаков\" data-toc-modified-id=\"Создание-признаков-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Создание признаков</a></span></li><li><span><a href=\"#Функции-обучения\" data-toc-modified-id=\"Функции-обучения-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Функции обучения</a></span></li></ul></li><li><span><a href=\"#Грузим-статистику\" data-toc-modified-id=\"Грузим-статистику-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Грузим статистику</a></span></li><li><span><a href=\"#Приведение-данных-к-норме\" data-toc-modified-id=\"Приведение-данных-к-норме-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Приведение данных к норме</a></span></li><li><span><a href=\"#Очистка-и-создание-признаков,-обучение\" data-toc-modified-id=\"Очистка-и-создание-признаков,-обучение-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Очистка и создание признаков, обучение</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Упрощенный вариант"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\YandexDisk\\Code\\.neural_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\YandexDisk\\Code\\.neural_env\\lib\\site-packages\\backtesting\\_plotting.py:50: UserWarning: Jupyter Notebook detected. Setting Bokeh output to notebook. This may not work in Jupyter clients without JavaScript support (e.g. PyCharm, Spyder IDE). Reset with `backtesting.set_bokeh_output(notebook=False)`.\n",
      "  warnings.warn('Jupyter Notebook detected. '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"p1001\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "const JS_MIME_TYPE = 'application/javascript';\n",
       "  const HTML_MIME_TYPE = 'text/html';\n",
       "  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  const CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    const script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    const cell = handle.cell;\n",
       "\n",
       "    const id = cell.output_area._bokeh_element_id;\n",
       "    const server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd_clean, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            const id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd_destroy);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    const output_area = handle.output_area;\n",
       "    const output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      const bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      const script_attrs = bk_div.children[0].attributes;\n",
       "      for (let i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      const toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    const events = require('base/js/events');\n",
       "    const OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  const NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    const el = document.getElementById(\"p1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.1.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.1.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.1.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.1.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.1.0.min.js\"];\n",
       "  const css_urls = [];\n",
       "\n",
       "  const inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "          for (let i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      const cell = $(document.getElementById(\"p1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"p1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.1.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.1.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.1.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.1.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.1.0.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n          for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\nif (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"p1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''Системные'''\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "# from tqdm import tqdm \n",
    "from pybit.unified_trading import HTTP\n",
    "import joblib\n",
    "\n",
    "'''База'''\n",
    "import talib\n",
    "# import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "\n",
    "'''Графики'''\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import dash\n",
    "from dash import dcc, html\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "'''Обучение'''\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from lightgbm import early_stopping\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "# Определяем устройство\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "'''Подготовка'''\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "'''Торговые агенты'''\n",
    "from backtesting import Backtest, Strategy\n",
    "\n",
    "\n",
    "# Настройка уровня логирования Optuna\n",
    "import logging\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "\n",
    "from config import (\n",
    "    api_key,\n",
    "    api_secret,\n",
    "    TELEGRAM_BOT_TOKEN, \n",
    "    TELEGRAM_CHAT_ID,\n",
    "    TP,\n",
    "    SL,\n",
    "    LEVERAGE,\n",
    "    LIMIT,\n",
    "    RS, \n",
    "    COMMISSION_BUY,\n",
    "    COMMISSION_SELL,\n",
    "    DEPOSIT,\n",
    "    WAY\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []\n",
    "all_data_crypt = []\n",
    "# Определяем конечную дату\n",
    "END_DATE = datetime.today()\n",
    "\n",
    "# Определяем начальную дату\n",
    "START_DATE = END_DATE - timedelta(days=0.1   * 365)\n",
    "\n",
    "# Вычисляем период между датами\n",
    "PERIOD = END_DATE - START_DATE\n",
    "\n",
    "# Если нужно вывести даты в формате 'YYYY-MM-DD'\n",
    "END_DATE_STR = END_DATE.strftime('%Y-%m-%d')\n",
    "START_DATE_STR = START_DATE.strftime('%Y-%m-%d')\n",
    "\n",
    "INTERVAL = 10\n",
    "COIN = 'DOGEUSDT'\n",
    "\n",
    "TEST_SIZE = 0.2\n",
    "THRESHOLD = 0.5\n",
    "\n",
    "COMMISSION = COMMISSION_BUY + COMMISSION_SELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функции загрузки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_coin_data(period, interval, coin):\n",
    "    limit = LIMIT\n",
    "    current_datetime = datetime.now()\n",
    "    end_date = current_datetime\n",
    "    start_date = end_date - period\n",
    "\n",
    "    # Проверяем, нужно ли разбивать запрос на части\n",
    "    results = []\n",
    "    if period.total_seconds() / (interval * 60) > (limit - 100):\n",
    "        print('Запрос частями, т.к. больше лимита')\n",
    "        total_parts = int(period.total_seconds() / (interval * 60 * (limit - 100))) + 1\n",
    "        for i in range(total_parts):\n",
    "            part_start_date = start_date + timedelta(minutes=i * (limit - 100) * interval)\n",
    "            part_end_date = part_start_date + timedelta(minutes=(limit - 100) * interval)\n",
    "            if part_end_date > end_date:\n",
    "                part_end_date = end_date\n",
    "\n",
    "            session = HTTP(\n",
    "                testnet=False,\n",
    "                api_key=api_key,\n",
    "                api_secret=api_secret,\n",
    "                )\n",
    "            response = session.get_kline(\n",
    "                category=\"linear\",\n",
    "                symbol=coin,\n",
    "                interval=str(interval),\n",
    "                start=int(part_start_date.timestamp() * 1000),\n",
    "                end=int(part_end_date.timestamp() * 1000),\n",
    "                limit=limit - 100,\n",
    "            )\n",
    "            if response.get('result', {}).get('list'):\n",
    "                results.extend(response['result']['list'])\n",
    "    else:\n",
    "        session = HTTP(\n",
    "                testnet=False,\n",
    "                api_key=api_key,\n",
    "                api_secret=api_secret,\n",
    "                )\n",
    "        response = session.get_kline(\n",
    "            category=\"linear\",\n",
    "            symbol=coin,\n",
    "            interval=str(interval),\n",
    "            start=int(start_date.timestamp() * 1000),\n",
    "            end=int(end_date.timestamp() * 1000),\n",
    "            limit=limit,\n",
    "        )\n",
    "        if response.get('result', {}).get('list'):\n",
    "            results = response['result']['list']\n",
    "\n",
    "    # Проверка и создание DataFrame\n",
    "    if not results:\n",
    "        raise ValueError(\"Не удалось получить данные из API.\")\n",
    "    \n",
    "    dates = [datetime.fromtimestamp(int(item[0]) / 1000) for item in results]\n",
    "    prices_open = [float(item[1]) for item in results]\n",
    "    prices_max = [float(item[2]) for item in results]\n",
    "    prices_min = [float(item[3]) for item in results]\n",
    "    prices_close = [float(item[4]) for item in results]\n",
    "    volume = [float(item[5]) for item in results]\n",
    "    df = pd.DataFrame({\n",
    "        'date': dates,\n",
    "        'open': prices_open,\n",
    "        'high': prices_max,\n",
    "        'low': prices_min,\n",
    "        'close': prices_close,\n",
    "        'volume': volume,\n",
    "    }).set_index('date')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подгрузка новых данных и предсказание на новых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_df_coin(df_existing, interval, coin):\n",
    "    limit = LIMIT\n",
    "    session = HTTP(\n",
    "                testnet=False,\n",
    "                api_key=api_key,\n",
    "                api_secret=api_secret,\n",
    "                )\n",
    "    current_datetime = datetime.now()\n",
    "    \n",
    "    # Определяем последний доступный временной момент в локальных данных\n",
    "    last_timestamp = df_existing.index.max() if not df_existing.empty else None\n",
    "    start_date = (last_timestamp + timedelta(minutes=interval)) if last_timestamp else (current_datetime - timedelta(days=30))  # 30 дней по умолчанию\n",
    "    \n",
    "    # Формируем запрос к API только для недостающих данных\n",
    "    response = session.get_kline(\n",
    "        category=\"linear\",\n",
    "        symbol=coin,\n",
    "        interval=str(interval),\n",
    "        start=int(start_date.timestamp() * 1000),\n",
    "        end=int(current_datetime.timestamp() * 1000),\n",
    "        limit=limit\n",
    "    )\n",
    "    results = response.get('result', {}).get('list', [])\n",
    "    \n",
    "    # Проверка и создание DataFrame для новых данных\n",
    "    if not results:\n",
    "#         print(\"Новых данных нет.\")\n",
    "        return df_existing\n",
    "\n",
    "    dates = [datetime.fromtimestamp(int(item[0]) / 1000) for item in results]\n",
    "    prices_open = [float(item[1]) for item in results]\n",
    "    prices_max = [float(item[2]) for item in results]\n",
    "    prices_min = [float(item[3]) for item in results]\n",
    "    prices_close = [float(item[4]) for item in results]\n",
    "    volume = [float(item[5]) for item in results]\n",
    "    df_new = pd.DataFrame({\n",
    "        'Date': dates,\n",
    "        'Open': prices_open,\n",
    "        'High': prices_max,\n",
    "        'Low': prices_min,\n",
    "        'Vlose': prices_close,\n",
    "        'Volume': volume,\n",
    "    }).set_index('Date')\n",
    "\n",
    "    # Объединяем старые и новые данные\n",
    "    df_updated = pd.concat([df_existing, df_new]).drop_duplicates()\n",
    "    return df_updated\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для добавления признаков\n",
    "def add_features(df, macd_fast=12, macd_slow=26, macd_signal=9, sma_fast=10, sma_slow=50, rsi_period=30):\n",
    "    df = df.copy()  # Создаем копию, чтобы не изменять исходный df\n",
    "    df.columns = df.columns.str.capitalize()\n",
    "    df['Close'] = df['Close'].astype(float)  # Принудительное преобразование в float\n",
    "    \n",
    "    # MACD, SMA, RSI\n",
    "    df['RSI'] = talib.RSI(df['Close'], timeperiod=rsi_period)\n",
    "    df['MACD'], df['MACD_signal'], _ = talib.MACD(df['Close'], fastperiod=macd_fast, slowperiod=macd_slow, signalperiod=macd_signal)\n",
    "    df['SMA_Fast'] = talib.SMA(df['Close'], timeperiod=sma_fast)\n",
    "    df['SMA_Slow'] = talib.SMA(df['Close'], timeperiod=sma_slow)\n",
    "\n",
    "    # Сигналы\n",
    "    df['Signal'] = np.where(\n",
    "        (df['MACD'] > df['MACD_signal']) & (df['SMA_Fast'] > df['SMA_Slow']) & (df['RSI'] < 40) , 1,  # Покупка \n",
    "        np.where((df['MACD'] < df['MACD_signal']) & (df['SMA_Fast'] < df['SMA_Slow']) & (df['RSI'] > 60), -1, 0)  #  Продажа / Ожидание \n",
    "    )\n",
    "\n",
    "    # Дополнительные RSI\n",
    "    df['RSI_1'] = talib.RSI(df['Close'], timeperiod=5)\n",
    "    df['RSI_2'] = talib.RSI(df['Close'], timeperiod=15)\n",
    "    df['RSI_3'] = talib.RSI(df['Close'], timeperiod=50)\n",
    "\n",
    "    # MACD с другими параметрами\n",
    "    df['MACD'], df['MACD_signal'], df['MACD_slow'] = talib.MACD(df['Close'], fastperiod=15, slowperiod=60, signalperiod=3)\n",
    "\n",
    "    # SMA с разными периодами\n",
    "    df['SMA_1'] = talib.SMA(df['Close'], timeperiod=7)\n",
    "    df['SMA_2'] = talib.SMA(df['Close'], timeperiod=15)\n",
    "    df['SMA_3'] = talib.SMA(df['Close'], timeperiod=30)\n",
    "    df['SMA_4'] = talib.SMA(df['Close'], timeperiod=100)\n",
    "\n",
    "    # Дополнительные признаки\n",
    "    df['d_min_max'] = df['High'] - df['Low']\n",
    "    df['d_open_max'] = df['Open'] - df['High']\n",
    "    df['d_open_min'] = df['Open'] - df['Low']\n",
    "\n",
    "    # Уровни поддержки и сопротивления\n",
    "    periods = [14, 20, 50, 100, 200]\n",
    "    df = calculate_levels(df, periods=periods)\n",
    "\n",
    "    # Дата и временные признаки\n",
    "    try:\n",
    "        df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "        df.set_index('Date', inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    df['weekday_number'] = df.index.weekday\n",
    "    df['week_number'] = df.index.isocalendar().week\n",
    "\n",
    "    # Динамика 1 час\n",
    "    df['динамика 1T'] = df['Close'] - df['Open']\n",
    "    df['динамика 1T'] = df['динамика 1T'].shift(1)\n",
    "\n",
    "    # Импульс\n",
    "    df['Импульс'] = 0\n",
    "    limit_dynamics = np.percentile(df['динамика 1T'].dropna(), 30)\n",
    "    df.loc[df['динамика 1T'] < limit_dynamics, 'Импульс'] = 1\n",
    "\n",
    "    # Дополнительные технические индикаторы\n",
    "    df['adx'] = talib.ADX(df['High'], df['Low'], df['Close'], timeperiod=9)\n",
    "    df['atr'] = talib.ATR(df['High'], df['Low'], df['Close'], timeperiod=9)\n",
    "    df['atr_norm'] = df['atr'] / df['Close']\n",
    "\n",
    "    df['upper_band'], df['middle_band'], df['lower_band'] = talib.BBANDS(df['Close'], timeperiod=7)\n",
    "    df['bb_width'] = (df['upper_band'] - df['lower_band']) / df['middle_band']\n",
    "\n",
    "    df['ema20'] = talib.EMA(df['Close'], timeperiod=20)\n",
    "    df['ema50'] = talib.EMA(df['Close'], timeperiod=50)\n",
    "    df['ema200'] = talib.EMA(df['Close'], timeperiod=200)\n",
    "\n",
    "    df['macd_2'], df['macd_signal_2'], df['macd_hist_2'] = talib.MACD(df['Close'], fastperiod=15, slowperiod=20, signalperiod=9)\n",
    "\n",
    "    df['sma_fast_2'] = talib.SMA(df['Close'], timeperiod=9)\n",
    "    df['sma_slow_2'] = talib.SMA(df['Close'], timeperiod=30)\n",
    "    df['tema'] = talib.TEMA(df['Close'], timeperiod=12)\n",
    "\n",
    "    # Лаги\n",
    "    df = create_lagged_features(df, 'tema', [2, 30])\n",
    "    df = create_lagged_features(df, 'RSI_1', [2, 30])\n",
    "    df = create_lagged_features(df, 'динамика 1T', [2, 30])\n",
    "    df = create_lagged_features(df, 'Импульс', [2, 30])\n",
    "\n",
    "    return df \n",
    "\n",
    "def calculate_levels(data, periods=[14]):\n",
    "    for period in periods:\n",
    "        high_col = f'high_max_{period}'\n",
    "        low_col = f'low_min_{period}'\n",
    "\n",
    "        data[high_col] = data['High'].rolling(window=period).max()\n",
    "        data[low_col] = data['Low'].rolling(window=period).min()\n",
    "\n",
    "    return data\n",
    "\n",
    "def create_lagged_features(data, column, lag_range):\n",
    "    \"\"\"\n",
    "    Создает лагированные признаки для указанного столбца.\n",
    "\n",
    "    :param data: DataFrame с исходными данными.\n",
    "    :param column: Название столбца, для которого нужно создать лаги.\n",
    "    :param lag_range: Список [начало, конец] или кортеж (начало, конец) диапазона лагов.\n",
    "    :return: DataFrame с добавленными лагированными колонками.\n",
    "    \"\"\"\n",
    "    start, end = lag_range\n",
    "    for i in range(start, end + 1):\n",
    "        lag_col = f\"{column}_lag_{i}h\"\n",
    "        data[lag_col] = data[column].shift(freq='h', periods=i)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функции обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяем нейросеть\n",
    "class SignalClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(SignalClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.softmax(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "# Функция обучения модели\n",
    "def train_pytorch_model(X_train, y_train, num_classes=3, model_filename=\"model.pth\", epochs=50, batch_size=32):\n",
    "    X_train = torch.tensor(X_train.astype(np.float32).values, dtype=torch.float32).to(device)\n",
    "    y_train = torch.tensor(y_train.astype(np.int64).values, dtype=torch.long).to(device)\n",
    "    dataset = TensorDataset(X_train, y_train)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    model = SignalClassifier(X_train.shape[1], num_classes).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for batch_X, batch_y in dataloader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    torch.save(model.state_dict(), model_filename)\n",
    "    print(f\"Модель сохранена в {model_filename}\")\n",
    "    return model\n",
    "\n",
    "# Функция предсказания\n",
    "def predict_pytorch_model(X_test, model_filename=\"model.pth\", num_classes=3):\n",
    "    model = SignalClassifier(X_test.shape[1], num_classes).to(device)\n",
    "    model.load_state_dict(torch.load(model_filename, map_location=device))\n",
    "    model.eval()\n",
    "    \n",
    "    X_test = torch.tensor(X_test.astype(np.float32).values, dtype=torch.float32).to(device)\n",
    "    with torch.no_grad():\n",
    "        predictions = model(X_test)\n",
    "    return np.argmax(predictions.cpu().numpy(), axis=1)\n",
    "\n",
    "# Подготовка данных\n",
    "def process_data(df_coin):\n",
    "    df_coin.columns = df_coin.columns.str.capitalize()\n",
    "    df_coin['Target'] = np.where(df_coin['Close'].shift(-1) > df_coin['Close'], 1, 0)\n",
    "    train_size = int(len(df_coin) * 0.9)\n",
    "    return df_coin[:train_size], df_coin[train_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyStrategy(Strategy):\n",
    "    model = None       # Параметр для модели ML\n",
    "    features = None    # Параметр для списка признаков\n",
    "    stop_loss = SL   # Уровень Stop Loss (_%)\n",
    "    take_profit = TP  # Уровень Take Profit (_%)\n",
    "    def init(self):\n",
    "        self.signal = self.I(lambda: self.data.Signal)\n",
    "        self.previous_signal = 0\n",
    "\n",
    "    def next(self):\n",
    "        \"\"\"\n",
    "        Основной цикл стратегии:\n",
    "        - Используем сигналы для открытия/закрытия позиций\n",
    "        \"\"\"\n",
    "        signal = self.data.df['Signal'].iloc[-1]  # Последний сигнал\n",
    "        current_price = self.data.Close[-1]      # Текущая цена закрытия\n",
    "        \n",
    "        if signal == 1:  # Покупка\n",
    "            self.buy(\n",
    "                sl=current_price * (1 - self.stop_loss),  # Уровень Stop Loss\n",
    "                tp=current_price * (1 + self.take_profit)  # Уровень Take Profit\n",
    "            )\n",
    "        elif signal == -1:  # Продажа\n",
    "            self.sell(\n",
    "                sl=current_price * (1 + self.stop_loss),  # Уровень Stop Loss\n",
    "                tp=current_price * (1 - self.take_profit)  # Уровень Take Profit\n",
    "            )\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Грузим статистику"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Запрос частями, т.к. больше лимита\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Не удалось получить данные из API.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data_temp \u001b[38;5;241m=\u001b[39m\u001b[43mfetch_coin_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPERIOD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mINTERVAL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCOIN\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_temp\u001b[38;5;241m.\u001b[39mcolumns, pd\u001b[38;5;241m.\u001b[39mMultiIndex):\n\u001b[0;32m      3\u001b[0m     data_temp\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m data_temp\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mdroplevel([\u001b[38;5;241m1\u001b[39m])\n",
      "Cell \u001b[1;32mIn[3], line 52\u001b[0m, in \u001b[0;36mfetch_coin_data\u001b[1;34m(period, interval, coin)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Проверка и создание DataFrame\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m results:\n\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mНе удалось получить данные из API.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     54\u001b[0m dates \u001b[38;5;241m=\u001b[39m [datetime\u001b[38;5;241m.\u001b[39mfromtimestamp(\u001b[38;5;28mint\u001b[39m(item[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1000\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m results]\n\u001b[0;32m     55\u001b[0m prices_open \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mfloat\u001b[39m(item[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m results]\n",
      "\u001b[1;31mValueError\u001b[0m: Не удалось получить данные из API."
     ]
    }
   ],
   "source": [
    "\n",
    "data_temp =fetch_coin_data(PERIOD, INTERVAL, COIN)\n",
    "if isinstance(data_temp.columns, pd.MultiIndex):\n",
    "    data_temp.columns = data_temp.columns.droplevel([1])\n",
    "data_temp = data_temp.reset_index(drop=False)\n",
    "data_temp.index.name = 'Price'\n",
    "#             data_temp.rename_axis(None, inplace=True)\n",
    "data_temp.columns.name = None\n",
    "data_temp = data_temp.reset_index(drop=True)\n",
    "# df.columns = df.columns.droplevel(1)\n",
    "data_temp.columns = data_temp.columns.str.lower()\n",
    "data_temp.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Приведение данных к норме"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_temp.copy() \n",
    "df = data.copy()\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.index.is_monotonic_increasing:\n",
    "    print(\"Индекс не отсортирован. Сортируем...\")\n",
    "    df = df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(method='ffill')\n",
    "df = pd.DataFrame(df.replace(to_replace=0, method='ffill'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.loc[(df['close'] > df['close'].rolling(window=3).mean() * 1.5) | (df['close'] < df['close'].rolling(window=3).mean() * 0.6)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Очистка и создание признаков, обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coin = df.copy()\n",
    "df_coin.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.index.is_monotonic_increasing:\n",
    "    print(\"Индекс не отсортирован. Сортируем...\")\n",
    "    df = df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_coin.columns = df_coin.columns.str.capitalize()\n",
    "\n",
    "\n",
    "# Добавляем целевую переменную\n",
    "df_coin['Target'] = np.where(df_coin['Close'].shift(-1) > df_coin['Close'], 1, 0)\n",
    "\n",
    "\n",
    "# Финальный бэктест с оптимальными параметрами\n",
    "train_size = int(len(df_coin) * 0.7)\n",
    "X_train, X_test = df_coin[:train_size], df_coin[train_size:]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Применение функций\n",
    "# best_params = optimize_hyperparameters(X_train)\n",
    "df_final_tr = add_features(X_train)\n",
    "df_final_tr['Signal'] = df_final_tr['Signal'] + 1\n",
    "\n",
    "X_train = X_train.drop(columns='Date')\n",
    "\n",
    "# Создаем объект StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# Обучаем scaler на тренировочных данных и трансформируем их\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "\n",
    "\n",
    "model = train_pytorch_model(df_final_tr.drop(columns=['Signal']), df_final_tr['Signal'])\n",
    "\n",
    "df_final = add_features(X_test)\n",
    "X_test = X_test.drop(columns='Date')\n",
    "# Применяем scaler к тестовым данным\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "predictions = predict_pytorch_model(df_final.drop(columns=['Signal']))\n",
    "\n",
    "# df_final['Signal'] = predictions - 1\n",
    "predicted_signal = predictions - 1\n",
    "df_final['Signal'] = np.where(df_final['Signal'] != predicted_signal, 0, df_final['Signal'])\n",
    "\n",
    "bt = Backtest(df_final, MyStrategy, cash=1000, commission=0.001, exclusive_orders=True)\n",
    "stats = bt.run()\n",
    "print(stats[:27])\n",
    "bt.plot(plot_equity=True, plot_drawdown=True, relative_equity=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Корреляция портфеля.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (.neural_env)",
   "language": "python",
   "name": ".neural_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "776px",
    "left": "22px",
    "top": "111.125px",
    "width": "222.4px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
